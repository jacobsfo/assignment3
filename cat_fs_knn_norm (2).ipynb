{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "class KNNClassifier():\n",
        "  def fit(self,X,y):\n",
        "    self.X=X\n",
        "    self.y=y.astype(int)\n",
        "  def predict(self,X,K,epsilon=1e-8):\n",
        "    N=len(X)\n",
        "    y_hat=np.zeros(N)\n",
        "\n",
        "    for i in range(N):\n",
        "      dist2 = np.sum((self.X - X[i])**2, axis=1)\n",
        "      idxt  = np.argsort(dist2)\n",
        "      gamma_k = 1/(np.sqrt(dist2[idxt]+epsilon))\n",
        "      y_hat[i] = np.bincount(self.y[idxt], weights=gamma_k).argmax()\n",
        "    return y_hat"
      ],
      "metadata": {
        "id": "8SByJGrBSW91"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def price_sq(x):\n",
        "  #if div by 20 then x 50\n",
        "  return x//50"
      ],
      "metadata": {
        "id": "BlkB_MFjO6M_"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y,y_hat):\n",
        "  return np.mean(y==y_hat)"
      ],
      "metadata": {
        "id": "BUIck8nIYH4g"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmmlOkkDy2HG",
        "outputId": "bd64b841-5785-4c9c-abe8-c6400fd55ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "74.52880952380953\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------------------------\n",
        "# 1. Imports\n",
        "# -------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Drive (Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 2. Load data\n",
        "# -------------------------------------------------------------\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ds/cleaned_final.csv\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 3. Basic cleaning\n",
        "# -------------------------------------------------------------\n",
        "df = df.drop(columns=[\"MLS\"])\n",
        "\n",
        "df['kitchen_features'] = df['kitchen_features'].fillna(\"Unknown\")\n",
        "df['floor_covering'] = df['floor_covering'].fillna(\"Unknown\")\n",
        "\n",
        "df['fireplaces'] = df['fireplaces'].apply(lambda x: 0 if str(x).lower() in [\"none\", \"0\"] else 1)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 4. Define features and target\n",
        "# -------------------------------------------------------------\n",
        "target = \"cat\"\n",
        "\n",
        "numeric_features = [\"longitude\", \"latitude\"]\n",
        "\n",
        "df['price/sqrft'] = round(df['sold_price']/df['sqrt_ft'], 2)\n",
        "\n",
        "X = df[numeric_features]\n",
        "y = df[target] = price_sq(df['price/sqrft'])\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 5. Train-test split\n",
        "# -------------------------------------------------------------\n",
        "X_train, X_test = X.iloc[:4000], X.iloc[4000:]\n",
        "y_train, y_test = y.iloc[:4000], y.iloc[4000:]\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 6. Hybrid Scaler: log1p + robust + standard (pure Pandas)\n",
        "# -------------------------------------------------------------\n",
        "X_train = pd.DataFrame(X_train, columns=numeric_features, index=X.iloc[:4000].index)\n",
        "X_test  = pd.DataFrame(X_test,  columns=numeric_features, index=X.iloc[4000:].index)\n",
        "\n",
        "# -------------------- STEP 1: Detect skewed positive columns --------------------\n",
        "# skew_vals = X_train.skew()\n",
        "# log_cols = [c for c in X_train.columns if abs(skew_vals[c]) > 1 and X_train[c].min() >= 0]\n",
        "\n",
        "# print(\"Log-transform columns:\", log_cols)\n",
        "\n",
        "# # Apply log1p to train & test on detected columns\n",
        "# X_train_h = X_train.copy()\n",
        "# X_test_h  = X_test.copy()\n",
        "\n",
        "# if log_cols:\n",
        "#     X_train_h[log_cols] = np.log1p(X_train_h[log_cols])\n",
        "#     X_test_h[log_cols]  = np.log1p(X_test_h[log_cols])\n",
        "\n",
        "# # -------------------- STEP 2: Detect outlier-heavy columns (for robust scaling) --------------------\n",
        "# # A big IQR suggests strong outliers\n",
        "# iqr_vals = X_train_h.quantile(0.75) - X_train_h.quantile(0.25)\n",
        "# iqr_threshold = iqr_vals.median() * 2   # adaptive threshold\n",
        "\n",
        "# robust_cols = [c for c in X_train_h.columns if iqr_vals[c] > iqr_threshold]\n",
        "\n",
        "# print(\"Robust-scale columns:\", robust_cols)\n",
        "\n",
        "# # The remaining columns will be standard scaled\n",
        "# standard_cols = [c for c in X_train_h.columns if c not in robust_cols]\n",
        "# print(\"Standard-scale columns:\", standard_cols)\n",
        "\n",
        "# # -------------------- STEP 3A: Fit robust scaler on TRAIN only --------------------\n",
        "# median_vals = X_train_h[robust_cols].median()\n",
        "# iqr_vals_robust = (X_train_h[robust_cols].quantile(0.75) -\n",
        "#                     X_train_h[robust_cols].quantile(0.25)).replace(0, 1.0)\n",
        "\n",
        "# # Apply robust scaling\n",
        "# X_train_h[robust_cols] = (X_train_h[robust_cols] - median_vals) / iqr_vals_robust\n",
        "# X_test_h[robust_cols]  = (X_test_h[robust_cols]  - median_vals) / iqr_vals_robust\n",
        "\n",
        "# # -------------------- STEP 3B: Fit standard scaler on TRAIN only --------------------\n",
        "# mean_vals = X_train_h[standard_cols].mean()\n",
        "# std_vals  = X_train_h[standard_cols].std().replace(0, 1.0)\n",
        "\n",
        "# # Apply standard scaling\n",
        "# X_train_h[standard_cols] = (X_train_h[standard_cols] - mean_vals) / std_vals\n",
        "# X_test_h[standard_cols]  = (X_test_h[standard_cols]  - mean_vals) / std_vals\n",
        "\n",
        "# # -------------------- Final scaled training/test sets --------------------\n",
        "# X_train = X_train_h\n",
        "# X_test  = X_test_h\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 7. Convert to numpy (as your KNN requires)\n",
        "# -------------------------------------------------------------\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 8. Fit and predict\n",
        "# -------------------------------------------------------------\n",
        "knn_instance = KNNClassifier()\n",
        "knn_instance.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn_instance.predict(X_test, K=5)\n",
        "mape = np.mean(np.abs((y_test-y_pred)/y_test*100))\n",
        "accuracy=100-mape\n",
        "print(accuracy)\n",
        "# ---------------------a----------------------------------------\n",
        "# 9. Evaluate\n",
        "# -------------------------------------------------------------\n",
        "# print(\"Model Accuracy: {:.2f}%\".format(accuracy(y_test, y_pred) * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xJm1GNFlzLIh"
      },
      "execution_count": 121,
      "outputs": []
    }
  ]
}