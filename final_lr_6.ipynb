{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/ds/cleaned_final.csv\"\n",
        "rseed = 42\n",
        "TFRAC = 0.8\n",
        "\n",
        "\n",
        "GD_LR0 = 1e-3\n",
        "GD_EPOCHS = 15000\n",
        "GD_VERBOSE = False\n",
        "\n",
        "\n",
        "df = pd.read_csv(path)\n",
        "# ---------------------------\n",
        "# 3. Basic cleaning (keep original behavior)\n",
        "# ---------------------------\n",
        "if 'floor_covering' in df.columns:\n",
        "    df['floor_covering'] = df['floor_covering'].fillna(df['floor_covering'].mode().iloc[0])\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Controlled feature engineering\n",
        "# ---------------------------\n",
        "# Log transforms to linearize skewed numeric features\n",
        "df['log_sqft'] = np.log1p(df['sqrt_ft'].fillna(0))\n",
        "df['log_acres'] = np.log1p(df['lot_acres'].fillna(0))\n",
        "# Single quadratic term (only one) to capture curvature\n",
        "df['sqft_sq'] = df['sqrt_ft'].fillna(0) ** 2\n",
        "\n",
        "# era: if year_built exists, create era buckets (same as your earlier implementation)\n",
        "if 'year_built' in df.columns:\n",
        "    df['era'] = pd.cut(\n",
        "        df['year_built'],\n",
        "        bins=[1800, 1945, 1970, 1990, 2000, 2010, 2030],\n",
        "        labels=[0, 1, 2, 3, 4, 5]\n",
        "    ).astype(int)\n",
        "else:\n",
        "    df['era'] = 0\n",
        "\n",
        "\n",
        "numeric_features = [\n",
        "    \"bathrooms\",\n",
        "    \"garage\",\n",
        "    \"log_sqft\",\n",
        "    \"log_acres\",\n",
        "    \"HOA\",\n",
        "    \"sqft_sq\"\n",
        "]\n",
        "\n",
        "# we'll replace the raw 'era' with era_median (target-encoding)\n",
        "categorical_features = [\"era\"]\n",
        "\n",
        "target_col = \"sold_price\"\n",
        "\n",
        "required = numeric_features + categorical_features + [target_col]\n",
        "\n",
        "# Create X, y (X is DataFrame for convenience)\n",
        "X_all = df[numeric_features + categorical_features].astype(float).reset_index(drop=True)\n",
        "y_all = df[target_col].astype(float).reset_index(drop=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Randomized train/test split using NumPy only\n",
        "# ---------------------------\n",
        "np.random.seed(rseed)\n",
        "indices = np.arange(len(X_all))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_size = int(TFRAC * len(indices))\n",
        "train_idx = indices[:train_size]\n",
        "test_idx  = indices[train_size:]\n",
        "\n",
        "X_train = X_all.iloc[train_idx].reset_index(drop=True)\n",
        "X_test  = X_all.iloc[test_idx].reset_index(drop=True)\n",
        "y_train = y_all.iloc[train_idx].reset_index(drop=True)\n",
        "y_test  = y_all.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "print(\"Train/Test sizes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# 8. Era target encoding (use training medians only)\n",
        "# ---------------------------\n",
        "era_median_map = y_train.groupby(X_train['era']).median().to_dict()\n",
        "global_median = y_train.median()\n",
        "# Map to train and test (test uses train mapping, fallback to global median)\n",
        "X_train['era_median'] = X_train['era'].map(era_median_map).fillna(global_median)\n",
        "X_test['era_median']  = X_test['era'].map(era_median_map).fillna(global_median)\n",
        "\n",
        "# Drop raw era column now (we have era_median)\n",
        "X_train = X_train.drop(columns=['era'])\n",
        "X_test  = X_test.drop(columns=['era'])\n",
        "\n",
        "# Add simple interaction: bathrooms * log_sqft (one extra predictive feature)\n",
        "X_train['bath_x_logsqft'] = X_train['bathrooms'].fillna(0) * X_train['log_sqft'].fillna(0)\n",
        "X_test['bath_x_logsqft']  = X_test['bathrooms'].fillna(0) * X_test['log_sqft'].fillna(0)\n",
        "\n",
        "# ---------------------------\n",
        "# 9. Feature scaling (fit on train, apply to test)\n",
        "# ---------------------------\n",
        "# Use mean/std (ddof=0) and replace zero std with 1\n",
        "X_mean = X_train.mean()\n",
        "X_std  = X_train.std(ddof=0).replace(0, 1.0)\n",
        "\n",
        "X_train_scaled = (X_train - X_mean) / X_std\n",
        "X_test_scaled  = (X_test - X_mean) / X_std\n",
        "\n",
        "# ---------------------------\n",
        "# 10. Target transform: log1p then standardize (train stats only)\n",
        "# ---------------------------\n",
        "y_train_log = np.log1p(y_train)\n",
        "y_test_log  = np.log1p(y_test)\n",
        "\n",
        "y_log_mean = y_train_log.mean()\n",
        "y_log_std  = y_train_log.std(ddof=0) if y_train_log.std(ddof=0) != 0 else 1.0\n",
        "\n",
        "y_train_stdlog = (y_train_log - y_log_mean) / y_log_std\n",
        "y_test_stdlog  = (y_test_log - y_log_mean) / y_log_std  # use training mean/std\n",
        "\n",
        "# ---------------------------\n",
        "# 11. Utility metrics (operate on original target scale)\n",
        "# ---------------------------\n",
        "def MAE(actual, pred):\n",
        "    actual = np.array(actual).flatten()\n",
        "    pred   = np.array(pred).flatten()\n",
        "    return np.mean(np.abs(actual - pred))\n",
        "\n",
        "def R2(actual, pred):\n",
        "    actual = np.array(actual).flatten()\n",
        "    pred   = np.array(pred).flatten()\n",
        "    ss_res = np.sum((actual - pred) ** 2)\n",
        "    ss_tot = np.sum((actual - np.mean(actual)) ** 2)\n",
        "    return 1 - ss_res / ss_tot if ss_tot != 0 else np.nan\n",
        "\n",
        "# ---------------------------\n",
        "# 12. Gradient Descent Linear Regression (NumPy)\n",
        "#    - operates on standardized log-target (y_train_stdlog)\n",
        "# ---------------------------\n",
        "class MVLinearRegression:\n",
        "    def __init__(self):\n",
        "        self.w = None  # shape (d,1)\n",
        "\n",
        "    def fit(self, X_df, y_stdlog, lr0=GD_LR0, epochs=GD_EPOCHS, verbose=False):\n",
        "        Xb = np.hstack([np.ones((len(X_df), 1)), X_df.values])  # bias + features\n",
        "        yv = y_stdlog.values.reshape(-1, 1)\n",
        "\n",
        "        n, d = Xb.shape\n",
        "        self.w = np.zeros((d, 1), dtype=float)\n",
        "\n",
        "        for epoch in range(int(epochs)):\n",
        "            y_pred = Xb @ self.w\n",
        "            grad = (2.0 / n) * (Xb.T @ (y_pred - yv))\n",
        "            # simple learning rate schedule\n",
        "            lr = lr0 / (1.0 + epoch / 5000.0)\n",
        "            self.w -= lr * grad\n",
        "\n",
        "            if verbose and (epoch % (max(1, int(epochs // 5))) == 0):\n",
        "                loss = np.mean((y_pred - yv) ** 2)\n",
        "                print(f\"[GD] epoch {epoch}/{int(epochs)} loss={loss:.6e}\")\n",
        "\n",
        "    def predict(self, X_df):\n",
        "        Xb = np.hstack([np.ones((len(X_df), 1)), X_df.values])\n",
        "        return (Xb @ self.w).flatten()\n",
        "\n",
        "# ---------------------------\n",
        "# 13. Stable Ridge (NumPy closed form)\n",
        "#    - solves for w in standardized log-target space\n",
        "# ---------------------------\n",
        "def fit_ridge(X_df, y_stdlog, lam=1.0, jitter=1e-6):\n",
        "    Xb = np.hstack([np.ones((len(X_df), 1)), X_df.values])\n",
        "    yv = y_stdlog.values.reshape(-1, 1)\n",
        "\n",
        "    d = Xb.shape[1]\n",
        "    I = np.eye(d)\n",
        "    I[0, 0] = 0.0  # do not regularize bias\n",
        "\n",
        "    A = Xb.T @ Xb + lam * I + jitter * np.eye(d)\n",
        "    b = Xb.T @ yv\n",
        "\n",
        "    w = np.linalg.solve(A, b)\n",
        "    return w\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 14. Train models\n",
        "# ---------------------------\n",
        "# GD model\n",
        "gd_model = MVLinearRegression()\n",
        "gd_model.fit(X_train_scaled, y_train_stdlog, lr0=GD_LR0, epochs=GD_EPOCHS, verbose=GD_VERBOSE)\n",
        "\n",
        "w_ridge = fit_ridge(X_train_scaled, y_train_stdlog, lam=1.0)\n",
        "# GD predictions (std log)\n",
        "y_pred_stdlog_gd = gd_model.predict(X_test_scaled)  # standardized log predictions\n",
        "# unstandardize -> log space\n",
        "y_pred_log_gd = (y_pred_stdlog_gd * y_log_std) + y_log_mean\n",
        "# invert log1p\n",
        "y_pred_gd = np.expm1(y_pred_log_gd)\n",
        "# Train predictions (for reporting)\n",
        "y_train_pred_stdlog_gd = gd_model.predict(X_train_scaled)\n",
        "y_train_pred_log_gd = (y_train_pred_stdlog_gd * y_log_std) + y_log_mean\n",
        "y_train_pred_gd = np.expm1(y_train_pred_log_gd)\n",
        "\n",
        "\n",
        "\n",
        "#predictions\n",
        "print(\"Train MAE:\", MAE(y_train, y_train_pred_gd))\n",
        "print(\"Train R2 :\", R2(y_train, y_train_pred_gd))\n",
        "print(\"Test MAE:\", MAE(y_test, y_pred_gd))\n",
        "print(\"Test R2 :\", R2(y_test, y_pred_gd))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKPlDGZl-yKd",
        "outputId": "54ebec07-9702-478d-e0fe-209f777a2d04"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded CSV with shape: (5000, 16)\n",
            "Train/Test sizes: (4000, 7) (1000, 7) (4000,) (1000,)\n",
            "Train MAE: 149869.5670333072\n",
            "Train R2 : 0.3533255734575861\n",
            "Test MAE: 147719.6955867197\n",
            "Test R2 : 0.32174986073238154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zx0tWOh7PR8"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}